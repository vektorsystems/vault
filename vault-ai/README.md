# ğŸš€ Vault AI - Deployment Configuration

This directory contains all the deployment files and configurations specifically for **Vault AI** (Open WebUI wrapper) deployment on Ubuntu servers.

## ğŸ“ Directory Structure

```
vault-ai/
â”œâ”€â”€ README.md                    # This file - main documentation
â”œâ”€â”€ docker-compose.vault.yaml   # Docker Compose configuration (remote services)
â”œâ”€â”€ deploy-ubuntu.sh            # Automated deployment script
â”œâ”€â”€ README-Ubuntu-Deploy.md     # Detailed deployment guide
â””â”€â”€ DEPLOYMENT-SUMMARY.md       # Quick reference summary
```

## ğŸ¯ What's Vault AI?

Vault AI is a private, self-hosted AI interface based on Open WebUI that provides:
- **Private AI conversations** with multiple models
- **Remote service architecture** for scalability
- **Easy deployment** on any Ubuntu 22.04+ server
- **Minimal resource requirements** (web interface only)

## âš¡ Quick Start

```bash
# 1. Navigate to vault-ai directory
cd vault-ai

# 2. Configure environment variables
cp ../.env.sample .env
nano .env  # Edit with your remote service URLs

# 3. Deploy automatically
chmod +x deploy-ubuntu.sh
./deploy-ubuntu.sh
```

## ğŸ”§ Configuration

This deployment uses **remote services only**:

| Service | Configuration | Example |
|---------|---------------|---------|
| **Ollama** | `OLLAMA_BASE_URL` | `http://your-ollama-server:11434` |
| **Database** | `DATABASE_URL` | `postgresql://user:pass@host:5432/db` |
| **OpenAI** | `OPENAI_API_KEY` | `sk-your-openai-key` |

## ğŸ“š Documentation

- **[README-Ubuntu-Deploy.md](./README-Ubuntu-Deploy.md)** - Complete deployment guide with security setup
- **[DEPLOYMENT-SUMMARY.md](./DEPLOYMENT-SUMMARY.md)** - Quick reference for all features
- **[docker-compose.vault.yaml](./docker-compose.vault.yaml)** - Production-ready Docker configuration

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Vault AI      â”‚    â”‚   Ollama        â”‚    â”‚   PostgreSQL    â”‚
â”‚   (This Config) â”‚â—„â”€â”€â–ºâ”‚   (Remote)      â”‚    â”‚   (Remote)      â”‚
â”‚   Web Interface â”‚    â”‚   AI Models     â”‚    â”‚   Database      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OpenAI API    â”‚
â”‚   (Remote)      â”‚
â”‚   GPT Models    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ… Features

- **ğŸª¶ Lightweight**: Only runs web interface (< 1GB RAM)
- **ğŸš€ Scalable**: Remote services can be more powerful
- **ğŸ”§ Flexible**: Use managed services or your own servers  
- **ğŸ’° Cost-effective**: Minimal server requirements
- **ğŸ”’ Secure**: Private deployment with HTTPS support

## ğŸ› ï¸ Useful Commands

```bash
# View status
docker-compose -f docker-compose.vault.yaml ps

# View logs
docker-compose -f docker-compose.vault.yaml logs -f

# Restart service
docker-compose -f docker-compose.vault.yaml restart

# Stop service
docker-compose -f docker-compose.vault.yaml down

# Update and restart
docker-compose -f docker-compose.vault.yaml pull
docker-compose -f docker-compose.vault.yaml up -d
```

## ğŸ†˜ Support

If you encounter issues:

1. **Check logs**: `docker-compose -f docker-compose.vault.yaml logs -f vault-ai`
2. **Verify configuration**: `docker-compose -f docker-compose.vault.yaml config`
3. **Test connectivity**: `curl -f http://localhost:8080/health`
4. **Review environment**: Check your `.env` file for correct remote service URLs

## ğŸš€ Access Your Vault AI

After successful deployment:
- **Local**: http://localhost:8080
- **External**: http://YOUR_SERVER_IP:8080
- **With SSL**: https://your-domain.com

---

**Ready to deploy your private AI interface!** ğŸ‰ 